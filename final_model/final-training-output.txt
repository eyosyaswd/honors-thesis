(honors-env) eyosyaswd@eyosyas-ubuntu:~/Documents/honors-thesis$ python main.py
polarity
-1    381
 0    385
 1    380
dtype: int64

Number of training data: 916
Number of testing data: 230

INITIALIZING CLASSIFIER...
vectorizer params: {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': None, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}
linear svc params {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

PERFORMING GRID SEARCH WITH CROSS VALIDATION...
# Tuning hyper-parameters for precision_micro

/home/eyosyaswd/Documents/honors-thesis/honors-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)

Best score and parameters set found on development set:
Score: 0.7565502183406113 Params: {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}

All grid scores on development set:
0.718 (+/-0.146) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.715 (+/-0.141) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.709 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.701 (+/-0.135) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.750 (+/-0.139) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.757 (+/-0.134) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.752 (+/-0.143) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.746 (+/-0.131) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.513 (+/-0.147) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.479 (+/-0.123) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.536 (+/-0.144) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.491 (+/-0.137) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.694 (+/-0.099) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.688 (+/-0.102) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.689 (+/-0.103) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.681 (+/-0.113) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}

Detaiiled classification report:
The model is trained on the full development set.
The scores are computed on the full evaluation set.
              precision    recall  f1-score   support

    negative       0.75      0.80      0.77        90
     neutral       0.82      0.73      0.77        70
    positive       0.71      0.73      0.72        70

   micro avg       0.76      0.76      0.76       230
   macro avg       0.76      0.75      0.76       230
weighted avg       0.76      0.76      0.76       230


Confusion matrix:
[[72  7 11]
 [ 9 51 10]
 [15  4 51]]


# Tuning hyper-parameters for recall_micro

/home/eyosyaswd/Documents/honors-thesis/honors-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)

Best score and parameters set found on development set:
Score: 0.7565502183406113 Params: {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}

All grid scores on development set:
0.718 (+/-0.146) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.715 (+/-0.141) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.709 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.701 (+/-0.135) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.750 (+/-0.139) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.757 (+/-0.134) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.752 (+/-0.143) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.746 (+/-0.131) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.513 (+/-0.147) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.478 (+/-0.121) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.536 (+/-0.144) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.491 (+/-0.137) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.693 (+/-0.101) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.687 (+/-0.101) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.692 (+/-0.099) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.681 (+/-0.113) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}

Detaiiled classification report:
The model is trained on the full development set.
The scores are computed on the full evaluation set.
              precision    recall  f1-score   support

    negative       0.75      0.80      0.77        90
     neutral       0.82      0.73      0.77        70
    positive       0.71      0.73      0.72        70

   micro avg       0.76      0.76      0.76       230
   macro avg       0.76      0.75      0.76       230
weighted avg       0.76      0.76      0.76       230


Confusion matrix:
[[72  7 11]
 [ 9 51 10]
 [15  4 51]]


# Tuning hyper-parameters for f1_micro

/home/eyosyaswd/Documents/honors-thesis/honors-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)

Best score and parameters set found on development set:
Score: 0.7565502183406113 Params: {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}

All grid scores on development set:
0.718 (+/-0.146) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.715 (+/-0.141) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.709 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.701 (+/-0.135) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.750 (+/-0.139) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.757 (+/-0.134) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.752 (+/-0.143) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.746 (+/-0.131) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.513 (+/-0.147) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.478 (+/-0.121) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.536 (+/-0.144) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.491 (+/-0.137) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.693 (+/-0.101) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.688 (+/-0.102) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.690 (+/-0.104) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.680 (+/-0.111) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}

Detaiiled classification report:
The model is trained on the full development set.
The scores are computed on the full evaluation set.
              precision    recall  f1-score   support

    negative       0.75      0.80      0.77        90
     neutral       0.82      0.73      0.77        70
    positive       0.71      0.73      0.72        70

   micro avg       0.76      0.76      0.76       230
   macro avg       0.76      0.75      0.76       230
weighted avg       0.76      0.76      0.76       230


Confusion matrix:
[[72  7 11]
 [ 9 51 10]
 [15  4 51]]


# Tuning hyper-parameters for accuracy

/home/eyosyaswd/Documents/honors-thesis/honors-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)

Best score and parameters set found on development set:
Score: 0.7565502183406113 Params: {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}

All grid scores on development set:
0.718 (+/-0.146) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.715 (+/-0.141) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.709 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.701 (+/-0.135) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.750 (+/-0.139) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.757 (+/-0.134) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.752 (+/-0.143) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.746 (+/-0.131) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.513 (+/-0.147) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.478 (+/-0.121) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.536 (+/-0.144) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.491 (+/-0.137) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.695 (+/-0.096) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.688 (+/-0.102) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.690 (+/-0.104) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.679 (+/-0.114) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}

Detaiiled classification report:
The model is trained on the full development set.
The scores are computed on the full evaluation set.
              precision    recall  f1-score   support

    negative       0.75      0.80      0.77        90
     neutral       0.82      0.73      0.77        70
    positive       0.71      0.73      0.72        70

   micro avg       0.76      0.76      0.76       230
   macro avg       0.76      0.75      0.76       230
weighted avg       0.76      0.76      0.76       230


Confusion matrix:
[[72  7 11]
 [ 9 51 10]
 [15  4 51]]


# Tuning hyper-parameters for None

/home/eyosyaswd/Documents/honors-thesis/honors-env/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.
  DeprecationWarning)

Best score and parameters set found on development set:
Score: 0.7565502183406113 Params: {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}

All grid scores on development set:
0.718 (+/-0.146) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.715 (+/-0.141) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.709 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.701 (+/-0.135) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.750 (+/-0.139) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.757 (+/-0.134) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.752 (+/-0.143) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.746 (+/-0.131) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': True, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.513 (+/-0.147) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.479 (+/-0.123) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.536 (+/-0.144) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.491 (+/-0.137) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.745 (+/-0.163) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.741 (+/-0.143) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.738 (+/-0.152) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.722 (+/-0.134) for {'linear_svc__C': 0.1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.695 (+/-0.093) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.684 (+/-0.099) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.690 (+/-0.104) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.679 (+/-0.114) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l1', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}
0.743 (+/-0.144) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.136) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 0.9, 'vectorizer__ngram_range': (1, 3)}
0.746 (+/-0.146) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 2)}
0.740 (+/-0.142) for {'linear_svc__C': 1, 'linear_svc__dual': False, 'linear_svc__loss': 'squared_hinge', 'linear_svc__penalty': 'l2', 'vectorizer__max_df': 1.0, 'vectorizer__ngram_range': (1, 3)}

Detaiiled classification report:
The model is trained on the full development set.
The scores are computed on the full evaluation set.
              precision    recall  f1-score   support

    negative       0.75      0.80      0.77        90
     neutral       0.82      0.73      0.77        70
    positive       0.71      0.73      0.72        70

   micro avg       0.76      0.76      0.76       230
   macro avg       0.76      0.75      0.76       230
weighted avg       0.76      0.76      0.76       230


Confusion matrix:
[[72  7 11]
 [ 9 51 10]
 [15  4 51]]




 (honors-env) eyosyaswd@eyosyas-ubuntu:~/Documents/honors-thesis$ python main.py
 polarity
 -1    381
  0    385
  1    380
 dtype: int64

 Number of training data: 916
 Number of testing data: 230

 CREATING FINAL MODEL...
 vectorizer params: {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 0.9, 'max_features': None, 'min_df': 1, 'ngram_range': (1, 3), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\b\\w\\w+\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}
 linear svc params {'C': 1.0, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'hinge', 'max_iter': 1000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': None, 'tol': 0.0001, 'verbose': 0}

 TRAINING FINAL MODEL...

 PICKLING MODEL...

 UNPICKLING MODEL...
 Detaiiled classification report for final model:
 The model is trained on the full development set.
 The scores are computed on the full evaluation set.
 0.7565217391304347
 <bound method Pipeline.get_params of Pipeline(memory=None,
      steps=[('vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',
         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',
         lowercase=True, max_df=0.9, max_features=None, min_df=1,
         ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=...e', max_iter=1000, multi_class='ovr',
      penalty='l2', random_state=None, tol=0.0001, verbose=0))])>
               precision    recall  f1-score   support

     negative       0.75      0.80      0.77        90
      neutral       0.82      0.73      0.77        70
     positive       0.71      0.73      0.72        70

    micro avg       0.76      0.76      0.76       230
    macro avg       0.76      0.75      0.76       230
 weighted avg       0.76      0.76      0.76       230


 Confusion matrix for final model:
 [[72  7 11]
  [ 9 51 10]
  [15  4 51]]
